# ğŸ“Š Stack ELK (Elasticsearch, Logstash, Kibana) pour GameV2

Solution complÃ¨te pour centraliser les logs des endpoints critiques et monitorer les conteneurs Docker.

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Docker Pods    â”‚
â”‚  (game-service, â”‚
â”‚  auth-service,  â”‚ â”€â”€logsâ”€â”€> â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  quiz-service)  â”‚           â”‚ Filebeat â”‚ â”€â”€> â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚ Logstash â”‚ â”€â”€> â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚ Elasticsearchâ”‚
                                                                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                                         â”‚
                                                                         v
                                                                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                                  â”‚  Kibana  â”‚
                                                                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Composants

- **Filebeat** : Collecte les logs de tous les conteneurs Docker (DaemonSet)
- **Logstash** : Traite, enrichit et parse les logs des endpoints critiques
- **Elasticsearch** : Stocke et indexe les logs
- **Kibana** : Interface de visualisation et d'analyse avec dashboards

## ğŸš€ DÃ©ploiement

### PrÃ©requis

- Cluster Kubernetes (Minikube, EKS, GKE, etc.)
- `kubectl` configurÃ©
- Au moins 4GB de RAM disponible
- Storage class configurÃ© (pour PersistentVolume)

### DÃ©ploiement automatique

```bash
chmod +x k8s/monitoring/elk/deploy-elk.sh
./k8s/monitoring/elk/deploy-elk.sh
```

### DÃ©ploiement manuel

```bash
# 1. CrÃ©er le namespace
kubectl create namespace elk

# 2. DÃ©ployer Elasticsearch
kubectl apply -f k8s/monitoring/elk/elasticsearch-deployment.yaml

# 3. Attendre qu'Elasticsearch soit prÃªt (2-3 minutes)
kubectl wait --for=condition=ready pod -l app=elasticsearch -n elk --timeout=300s

# 4. DÃ©ployer Logstash
kubectl apply -f k8s/monitoring/elk/logstash-deployment.yaml

# 5. DÃ©ployer Filebeat
kubectl apply -f k8s/monitoring/elk/filebeat-daemonset.yaml

# 6. DÃ©ployer Kibana
kubectl apply -f k8s/monitoring/elk/kibana-deployment.yaml
```

## ğŸ” AccÃ¨s Ã  Kibana

### Sur Minikube local

```bash
kubectl port-forward -n elk service/kibana 5601:5601
```

Puis ouvrez : http://localhost:5601

### Sur cluster avec NodePort

AccÃ©dez via : `http://<NODE_IP>:30601`

### Sur EKS/GKE avec LoadBalancer

Modifiez le service Kibana pour utiliser `type: LoadBalancer` :

```yaml
apiVersion: v1
kind: Service
metadata:
  name: kibana
  namespace: elk
spec:
  type: LoadBalancer  # Au lieu de NodePort
  ports:
  - port: 5601
    targetPort: 5601
```

## ğŸ“Š Configuration des Indices

### Indices crÃ©Ã©s automatiquement

- **`gamev2-logs-YYYY.MM.dd`** : Tous les logs
- **`gamev2-errors-YYYY.MM.dd`** : Logs d'erreur uniquement
- **`gamev2-critical-YYYY.MM.dd`** : Logs des endpoints critiques

### Endpoints critiques monitorÃ©s

#### Game Service
- `POST /game/answer` - Soumission de rÃ©ponses
- `GET /game/score/:playerId` - RÃ©cupÃ©ration des scores
- `GET /game/leaderboard` - Classement
- `POST /game/start` - DÃ©marrage du jeu
- `POST /game/next` - Question suivante
- `POST /game/end` - Fin du jeu
- `GET /game/results` - RÃ©sultats

#### Auth Service
- `POST /auth/admin/login` - Connexion admin
- `POST /auth/players/register` - Inscription joueur
- `GET /auth/players` - Liste des joueurs

#### Quiz Service
- `GET /quiz/all` - Liste des questions
- `GET /quiz/full` - Questions complÃ¨tes
- `POST /quiz/create` - CrÃ©ation de question
- `GET /quiz/verify/:id` - VÃ©rification de rÃ©ponse

#### WebSocket
- Connexions/dÃ©connexions
- Ã‰vÃ©nements `register`, `game:started`, `question:next`
- Erreurs de connexion

## ğŸ” Utilisation dans Kibana

### 1. CrÃ©er un index pattern

1. Allez dans **Management** â†’ **Stack Management** â†’ **Index Patterns**
2. Cliquez sur **Create index pattern**
3. Entrez : `gamev2-logs-*`
4. SÃ©lectionnez `@timestamp` comme time field
5. Cliquez sur **Create index pattern**

RÃ©pÃ©tez pour :
- `gamev2-errors-*`
- `gamev2-critical-*`

### 2. RequÃªtes KQL de base

Dans **Discover** :

#### Voir tous les logs
```
*
```

#### Logs d'un service spÃ©cifique
```
container_name: "game-service"
```

#### Logs des endpoints critiques
```
critical_endpoint: true
```

#### Logs d'erreur
```
log_level: "error"
```

#### Logs d'un endpoint spÃ©cifique
```
endpoint_type: "answer" AND container_name: "game-service"
```

#### Logs WebSocket
```
endpoint_type: "websocket"
```

#### Rechercher par player ID
```
player_id: "p1234567890"
```

#### Rechercher par question ID
```
question_id: "q1764929000053"
```

#### Logs des derniÃ¨res 15 minutes
```
@timestamp >= now()-15m
```

### 3. Dashboards prÃ©-configurÃ©s

#### Dashboard "Endpoints Critiques"

CrÃ©er un dashboard avec les visualisations suivantes :

**1. Graphique des requÃªtes par endpoint**
- Type : Line chart
- Query : `critical_endpoint: true`
- X-axis : `@timestamp` (histogram)
- Y-axis : Count
- Split by : `endpoint_type`

**2. Taux d'erreur par service**
- Type : Pie chart
- Query : `log_level: "error"`
- Split by : `container_name`

**3. Temps de rÃ©ponse moyen**
- Type : Metric
- Query : `has_performance_metric: true`
- Metric : Average of `response_time`

**4. Top 10 des erreurs**
- Type : Data table
- Query : `log_level: "error"`
- Columns : `@timestamp`, `container_name`, `message`
- Sort by : `@timestamp` (desc)

**5. Logs WebSocket en temps rÃ©el**
- Type : Timeline
- Query : `endpoint_type: "websocket"`
- X-axis : `@timestamp`
- Y-axis : `event_name`

### 4. Alertes

CrÃ©er des alertes dans Kibana :

**1. Trop d'erreurs**
- Condition : `count(log_level: "error") > 50` sur 5 minutes
- Action : Email ou webhook

**2. Endpoint critique en erreur**
- Condition : `critical_endpoint: true AND log_level: "error"` sur 1 minute
- Action : Notification Slack

**3. Service down**
- Condition : Pas de logs depuis 2 minutes pour un service
- Action : PagerDuty

## ğŸ“ˆ MÃ©triques importantes

### Endpoints critiques

- **Taux de succÃ¨s** : `(count(http_status: 2*) / count(*)) * 100`
- **Temps de rÃ©ponse moyen** : `avg(response_time)`
- **Nombre de requÃªtes par minute** : `count() over time`
- **Top erreurs** : `group by message where log_level: "error"`

### Performance

- **Latence p95** : `percentile(response_time, 95)`
- **Throughput** : `count() per minute`
- **Erreurs par service** : `count(log_level: "error") group by container_name`

### WebSocket

- **Connexions actives** : `count(endpoint_type: "websocket" AND connected_status: "true")`
- **DÃ©connexions** : `count(endpoint_type: "websocket" AND connected_status: "false")`
- **Erreurs de connexion** : `count(endpoint_type: "websocket" AND log_level: "error")`

## ğŸ› ï¸ Maintenance

### VÃ©rifier le statut

```bash
# VÃ©rifier les pods
kubectl get pods -n elk

# VÃ©rifier les logs
kubectl logs -f -n elk -l app=elasticsearch
kubectl logs -f -n elk -l app=logstash
kubectl logs -f -n elk -l app=filebeat
kubectl logs -f -n elk -l app=kibana
```

### VÃ©rifier les indices Elasticsearch

```bash
# Lister les indices
kubectl exec -it -n elk deployment/elasticsearch -- curl http://localhost:9200/_cat/indices?v

# Voir les statistiques
kubectl exec -it -n elk deployment/elasticsearch -- curl http://localhost:9200/_stats

# Voir la santÃ© du cluster
kubectl exec -it -n elk deployment/elasticsearch -- curl http://localhost:9200/_cluster/health?pretty
```

### RedÃ©marrer un service

```bash
kubectl rollout restart deployment/elasticsearch -n elk
kubectl rollout restart deployment/logstash -n elk
kubectl rollout restart deployment/kibana -n elk
kubectl rollout restart daemonset/filebeat -n elk
```

### Nettoyer les anciens indices

```bash
# Supprimer les indices de plus de 30 jours
kubectl exec -it -n elk deployment/elasticsearch -- curl -X DELETE "http://localhost:9200/gamev2-logs-$(date -d '30 days ago' +%Y.%m.%d)"
```

### Augmenter la rÃ©tention

Modifiez la configuration Logstash pour changer la rÃ©tention :

```yaml
# Dans logstash-pipeline ConfigMap
output {
  elasticsearch {
    index => "gamev2-logs-%{+YYYY.MM.dd}"
    # Ajouter une politique ILM (Index Lifecycle Management)
  }
}
```

## ğŸ”§ Configuration avancÃ©e

### Personnaliser les filtres Logstash

Ã‰ditez le ConfigMap `logstash-pipeline` :

```bash
kubectl edit configmap logstash-pipeline -n elk
```

Puis redÃ©marrez Logstash :

```bash
kubectl rollout restart deployment/logstash -n elk
```

### Ajouter des champs personnalisÃ©s

Dans Logstash, ajoutez des champs :

```ruby
filter {
  if [container_name] == "game-service" {
    mutate {
      add_field => {
        "environment" => "production"
        "team" => "backend"
      }
    }
  }
}
```

### Configurer Filebeat pour des logs spÃ©cifiques

Modifiez le ConfigMap `filebeat-config` pour inclure/exclure des logs :

```yaml
filebeat.inputs:
- type: container
  paths:
    - /var/log/containers/*.log
  exclude_lines: ['DEBUG', 'TRACE']  # Exclure les logs de debug
  include_lines: ['ERROR', 'WARN', 'INFO']  # Inclure seulement certains niveaux
```

## ğŸ“ Notes importantes

- **Stockage** : Elasticsearch utilise un PersistentVolume de 20GB. Ajustez selon vos besoins.
- **Ressources** : Les ressources par dÃ©faut sont minimales. Augmentez pour la production.
- **SÃ©curitÃ©** : La sÃ©curitÃ© X-Pack est dÃ©sactivÃ©e par dÃ©faut. Activez-la pour la production.
- **Performance** : Pour de gros volumes, augmentez les rÃ©pliques et les ressources.

## ğŸ› DÃ©pannage

### Elasticsearch ne dÃ©marre pas

```bash
# VÃ©rifier les logs
kubectl logs -n elk -l app=elasticsearch

# VÃ©rifier les Ã©vÃ©nements
kubectl describe pod -n elk -l app=elasticsearch

# VÃ©rifier le PVC
kubectl get pvc -n elk
```

### Logstash ne reÃ§oit pas de logs

```bash
# VÃ©rifier la connexion Filebeat â†’ Logstash
kubectl logs -n elk -l app=filebeat | grep logstash

# VÃ©rifier que Logstash Ã©coute
kubectl exec -it -n elk deployment/logstash -- netstat -tlnp | grep 5044
```

### Filebeat ne collecte pas les logs

```bash
# VÃ©rifier les permissions
kubectl exec -it -n elk daemonset/filebeat -- ls -la /var/log/containers/

# VÃ©rifier la configuration
kubectl exec -it -n elk daemonset/filebeat -- cat /etc/filebeat.yml
```

### Kibana ne se connecte pas Ã  Elasticsearch

```bash
# VÃ©rifier la configuration
kubectl exec -it -n elk deployment/kibana -- env | grep ELASTICSEARCH

# Tester la connexion depuis Kibana
kubectl exec -it -n elk deployment/kibana -- curl http://elasticsearch:9200
```

## ğŸ”— Ressources

- [Documentation Elasticsearch](https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html)
- [Documentation Logstash](https://www.elastic.co/guide/en/logstash/current/index.html)
- [Documentation Filebeat](https://www.elastic.co/guide/en/beats/filebeat/current/index.html)
- [Documentation Kibana](https://www.elastic.co/guide/en/kibana/current/index.html)
- [Grok Patterns](https://github.com/elastic/logstash/blob/v1.4.2/patterns/grok-patterns)

