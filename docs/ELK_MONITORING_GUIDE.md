# ğŸ“Š Guide complet : Monitoring avec ELK Stack

Guide dÃ©taillÃ© pour implÃ©menter Elasticsearch, Logstash et Kibana pour centraliser les logs des endpoints critiques et monitorer les conteneurs Docker.

## ğŸ“‹ Table des matiÃ¨res

1. [Vue d'ensemble](#vue-densemble)
2. [Architecture](#architecture)
3. [DÃ©ploiement](#dÃ©ploiement)
4. [Configuration](#configuration)
5. [Utilisation](#utilisation)
6. [Dashboards](#dashboards)
7. [Alertes](#alertes)
8. [Maintenance](#maintenance)

## ğŸ¯ Vue d'ensemble

Le stack ELK permet de :
- **Centraliser** tous les logs des conteneurs Docker
- **Parser** et **enrichir** les logs des endpoints critiques
- **Visualiser** les mÃ©triques en temps rÃ©el avec Kibana
- **DÃ©tecter** les problÃ¨mes rapidement avec des alertes

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Kubernetes Cluster                        â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ game-service â”‚  â”‚ auth-service â”‚  â”‚ quiz-service â”‚    â”‚
â”‚  â”‚   (Pod)      â”‚  â”‚   (Pod)      â”‚  â”‚   (Pod)      â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚         â”‚                 â”‚                 â”‚             â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                           â”‚                                â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚                    â”‚  Filebeat   â”‚                         â”‚
â”‚                    â”‚ (DaemonSet) â”‚                         â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â”‚                           â”‚                                â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚                    â”‚  Logstash   â”‚                         â”‚
â”‚                    â”‚ (Deployment)â”‚                         â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â”‚                           â”‚                                â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚                    â”‚Elasticsearch â”‚                         â”‚
â”‚                    â”‚(StatefulSet)â”‚                         â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â”‚                           â”‚                                â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚                    â”‚   Kibana     â”‚                         â”‚
â”‚                    â”‚ (Deployment) â”‚                         â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Flux de donnÃ©es

1. **Collecte** : Filebeat collecte les logs de tous les conteneurs
2. **Traitement** : Logstash parse et enrichit les logs
3. **Stockage** : Elasticsearch indexe les logs
4. **Visualisation** : Kibana affiche les dashboards

## ğŸš€ DÃ©ploiement

### PrÃ©requis

- Cluster Kubernetes (Minikube, EKS, GKE, etc.)
- `kubectl` configurÃ©
- Au moins 4GB de RAM disponible
- Storage class configurÃ©

### DÃ©ploiement rapide

```bash
cd /path/to/gameV2
./k8s/monitoring/elk/deploy-elk.sh
```

### VÃ©rification

```bash
# VÃ©rifier que tous les pods sont prÃªts
kubectl get pods -n elk

# Devrait afficher :
# NAME                            READY   STATUS    RESTARTS   AGE
# elasticsearch-0                 1/1     Running   0          2m
# filebeat-xxxxx                  1/1     Running   0          1m
# kibana-xxxxx                    1/1     Running   0          1m
# logstash-xxxxx                  1/1     Running   0          1m
```

## âš™ï¸ Configuration

### Endpoints critiques configurÃ©s

Le fichier `logstash.conf` parse automatiquement :

#### Game Service
- `POST /game/answer` - Extraction : `player_id`, `question_id`, `is_correct`
- `POST /game/start` - Tag : `critical_endpoint: true`
- `POST /game/next` - Tag : `critical_endpoint: true`
- `GET /game/leaderboard` - Tag : `critical_endpoint: true`

#### Auth Service
- `POST /auth/admin/login` - Tag : `critical_endpoint: true`
- `POST /auth/players/register` - Tag : `critical_endpoint: true`

#### Quiz Service
- `GET /quiz/verify/:id` - Extraction : `question_id`
- `POST /quiz/create` - Tag : `critical_endpoint: true`

### Champs extraits automatiquement

- `player_id` : ID du joueur
- `player_name` : Nom du joueur
- `question_id` : ID de la question
- `is_correct` : RÃ©ponse correcte ou non
- `http_status` : Code HTTP de la rÃ©ponse
- `endpoint_type` : Type d'endpoint (answer, auth, quiz, websocket)
- `log_level` : Niveau de log (error, warn, info, debug)
- `critical_endpoint` : Boolean indiquant si c'est un endpoint critique

## ğŸ“Š Utilisation

### AccÃ¨s Ã  Kibana

```bash
# Port-forward
kubectl port-forward -n elk service/kibana 5601:5601

# Ou via NodePort
# http://<NODE_IP>:30601
```

### CrÃ©er un index pattern

1. Allez dans **Management** â†’ **Stack Management** â†’ **Index Patterns**
2. Cliquez sur **Create index pattern**
3. Entrez : `gamev2-logs-*`
4. SÃ©lectionnez `@timestamp` comme time field
5. Cliquez sur **Create index pattern**

### RequÃªtes KQL utiles

#### Tous les endpoints critiques
```
critical_endpoint: true
```

#### Erreurs sur les endpoints critiques
```
critical_endpoint: true AND log_level: "error"
```

#### RÃ©ponses des joueurs
```
endpoint_type: "answer" AND container_name: "game-service"
```

#### Temps de rÃ©ponse > 1 seconde
```
has_performance_metric: true AND response_time > 1000
```

#### Erreurs WebSocket
```
endpoint_type: "websocket" AND log_level: "error"
```

## ğŸ“ˆ Dashboards

### Dashboard "Endpoints Critiques"

CrÃ©er un dashboard avec :

1. **Graphique des requÃªtes par endpoint**
   - Type : Line chart
   - Query : `critical_endpoint: true`
   - X-axis : `@timestamp` (histogram)
   - Y-axis : Count
   - Split by : `endpoint_type`

2. **Taux de succÃ¨s par endpoint**
   - Type : Gauge
   - Query : `critical_endpoint: true`
   - Metric : `(count(http_status: 2*) / count(*)) * 100`

3. **Top 10 des erreurs**
   - Type : Data table
   - Query : `log_level: "error"`
   - Columns : `@timestamp`, `container_name`, `message`

### Dashboard "Performance"

1. **Temps de rÃ©ponse moyen**
   - Type : Metric
   - Query : `has_performance_metric: true`
   - Metric : Average of `response_time`

2. **Latence p95**
   - Type : Line chart
   - Query : `has_performance_metric: true`
   - Metric : Percentile of `response_time` (95)

## ğŸš¨ Alertes

### CrÃ©er une alerte

1. Allez dans **Management** â†’ **Stack Management** â†’ **Rules and Connectors**
2. Cliquez sur **Create rule**
3. Configurez :
   - **Name** : "Trop d'erreurs sur endpoints critiques"
   - **Query** : `critical_endpoint: true AND log_level: "error"`
   - **Condition** : `count() > 50` sur 5 minutes
   - **Action** : Email ou webhook

### Alertes recommandÃ©es

1. **Trop d'erreurs** : `count(log_level: "error") > 50` sur 5 minutes
2. **Service down** : Pas de logs depuis 2 minutes
3. **Temps de rÃ©ponse Ã©levÃ©** : `avg(response_time) > 5000` sur 10 minutes
4. **Taux d'erreur Ã©levÃ©** : `(count(http_status: [45]*) / count(*)) * 100 > 10%`

## ğŸ”§ Maintenance

### Nettoyer les anciens indices

```bash
# Supprimer les indices de plus de 30 jours
kubectl exec -it -n elk deployment/elasticsearch -- \
  curl -X DELETE "http://localhost:9200/gamev2-logs-$(date -d '30 days ago' +%Y.%m.%d)"
```

### VÃ©rifier l'espace disque

```bash
kubectl exec -it -n elk deployment/elasticsearch -- \
  curl http://localhost:9200/_cat/allocation?v
```

### RedÃ©marrer un service

```bash
kubectl rollout restart deployment/elasticsearch -n elk
kubectl rollout restart deployment/logstash -n elk
kubectl rollout restart deployment/kibana -n elk
```

## ğŸ“ Notes

- Les logs sont conservÃ©s 7 jours par dÃ©faut
- Ajustez les ressources selon votre charge
- Activez la sÃ©curitÃ© X-Pack pour la production
- Configurez des sauvegardes rÃ©guliÃ¨res d'Elasticsearch

## ğŸ”— Ressources

- [Documentation ELK](https://www.elastic.co/guide/index.html)
- [KQL Query Language](https://www.elastic.co/guide/en/kibana/current/kuery-query.html)
- [Grok Patterns](https://github.com/elastic/logstash/blob/v1.4.2/patterns/grok-patterns)

